{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "📊Loading Data\n",
        "\n",
        "download and extract a housing dataset\n",
        "\n",
        "The extracted data is then loaded into a Pandas DataFrame for further analysis"
      ],
      "metadata": {
        "id": "nAF6PEgShboo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import tarfile\n",
        "import urllib.request\n",
        "\n",
        "def load_housing_data():\n",
        "    \"\"\"\n",
        "    This function checks if the housing dataset exists locally.\n",
        "    If not, it downloads, extracts, and loads it into a Pandas DataFrame.\n",
        "    \"\"\"\n",
        "    tarball_path = Path('datasets/housing.tgz')\n",
        "\n",
        "    if not tarball_path.is_file():\n",
        "        Path('datasets').mkdir(parents=True, exist_ok=True)\n",
        "        url = \"https://github.com/ageron/data/raw/main/housing.tgz\"\n",
        "\n",
        "        urllib.request.urlretrieve(url, tarball_path)\n",
        "\n",
        "        with tarfile.open(tarball_path) as housing_tarball:\n",
        "            housing_tarball.extractall(path='datasets')\n",
        "\n",
        "    return pd.read_csv(Path('datasets/housing/housing.csv'))\n",
        "\n",
        "housing = load_housing_data()\n"
      ],
      "metadata": {
        "id": "SOoCII29jUz2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "housing.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HWrGPNlkzxs",
        "outputId": "cea1717c-961c-4aa6-8221-1711b0160248"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 20640 entries, 0 to 20639\n",
            "Data columns (total 10 columns):\n",
            " #   Column              Non-Null Count  Dtype  \n",
            "---  ------              --------------  -----  \n",
            " 0   longitude           20640 non-null  float64\n",
            " 1   latitude            20640 non-null  float64\n",
            " 2   housing_median_age  20640 non-null  float64\n",
            " 3   total_rooms         20640 non-null  float64\n",
            " 4   total_bedrooms      20433 non-null  float64\n",
            " 5   population          20640 non-null  float64\n",
            " 6   households          20640 non-null  float64\n",
            " 7   median_income       20640 non-null  float64\n",
            " 8   median_house_value  20640 non-null  float64\n",
            " 9   ocean_proximity     20640 non-null  object \n",
            "dtypes: float64(9), object(1)\n",
            "memory usage: 1.6+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "→ Data Shuffling and Splitting\n",
        "\n",
        "Using np.random.permutation()"
      ],
      "metadata": {
        "id": "bPOE4jxQo0Sc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.random.seed(42) #🌱 To specify a fixed starting point for the random generation process, ensuring that each run of the code produces the same results\n",
        "\n",
        "def shuffle_and_split_data(data,test_ratio):\n",
        "  \"\"\"\n",
        "    This function shuffles the dataset randomly and splits it into training and test sets\n",
        "     Arguments:\n",
        "    - data: Pandas DataFrame, the dataset to split\n",
        "    - test_ratio: float, the proportion of data to allocate to the test set\n",
        "\n",
        "    Returns:\n",
        "    - train_set: DataFrame containing the training data\n",
        "    - test_set: DataFrame containing the test data\n",
        "  \"\"\"\n",
        "  shuffled_indices = np.random.permutation(len(data)) # Shuffle the input data\n",
        "\n",
        "  print('Total number of shuffled indecies', len(shuffled_indices)) # Print The total number of indices that were shuffled\n",
        "  test_set_size = int(len(data)*test_ratio) # Calculate the test set size\n",
        "  test_indices = shuffled_indices[:test_set_size]\n",
        "  train_indices = shuffled_indices[test_set_size:]\n",
        "  return data.iloc[train_indices],data.iloc[test_indices]\n",
        "train_set,test_set = shuffle_and_split_data(housing,0.2) # shuffle_and_split_data() to split housing data using 20% ​​for testing and 80% for training\n",
        "print(\"First 5 rows of training set:\")\n",
        "print(train_set.head())\n",
        "print('------------------------------------------------------------------------')\n",
        "print(\"Training set size: \",len(train_set))\n",
        "print(\"Test set size: \",len(test_set))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjwaRFhzo5H2",
        "outputId": "200dd2d1-aa6c-4ac8-c73e-2a0d8f6edb0d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of shuffled indecies 20640\n",
            "First 5 rows of training set:\n",
            "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
            "14196    -117.22     32.75                34.0       6001.0          1111.0   \n",
            "8267     -117.03     32.69                10.0        901.0           163.0   \n",
            "17445    -122.27     37.74                28.0       6909.0          1554.0   \n",
            "14265    -121.82     37.25                25.0       4021.0           634.0   \n",
            "2271     -115.98     33.32                 8.0        240.0            46.0   \n",
            "\n",
            "       population  households  median_income  median_house_value  \\\n",
            "14196      2654.0      1072.0         4.5878            291000.0   \n",
            "8267        698.0       167.0         4.6648            156100.0   \n",
            "17445      2974.0      1484.0         3.6875            353900.0   \n",
            "14265      2178.0       650.0         5.1663            241200.0   \n",
            "2271         63.0        24.0         1.4688             53800.0   \n",
            "\n",
            "      ocean_proximity  \n",
            "14196      NEAR OCEAN  \n",
            "8267       NEAR OCEAN  \n",
            "17445        NEAR BAY  \n",
            "14265       <1H OCEAN  \n",
            "2271           INLAND  \n",
            "------------------------------------------------------------------------\n",
            "Training set size:  16512\n",
            "Test set size:  4128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "→ Data Splitting\n",
        "\n",
        "Using train_test_split"
      ],
      "metadata": {
        "id": "RE79szhkvH7Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Divide median_income column into 5 categories (income_cat) using (bins)\n",
        "# labels=[1, 2, 3, 4, 5] gives each category a serial number\n",
        "# pd.cut() is used to classify median_income into categories (income_cat)\n",
        "housing['income_cat'] = pd.cut(housing['median_income'],bins=[0.,1.5,3.0,4.5,6.,np.inf],labels=[1,2,3,4,5])\n",
        "print(housing['income_cat']) # Print income classifications for each row in the data\n",
        "\n",
        "# Split data using train_test_split()\n",
        "# test_size : 20% , training_set : 80%\n",
        "# stratify=housing['income_cat'] : It ensures that the distribution of income_cat in the test set is almost identical to its distribution in the training set\n",
        "# random_state=42 : Ensures that the results will be repeated every time the code is run.\n",
        "strat_train_set,strat_test_set = train_test_split(housing,test_size=0.2,stratify=housing['income_cat'],random_state=42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4JN5VEBvRYb",
        "outputId": "a41cbde9-b173-4063-c555-8073422f6af6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0        5\n",
            "1        5\n",
            "2        5\n",
            "3        4\n",
            "4        3\n",
            "        ..\n",
            "20635    2\n",
            "20636    2\n",
            "20637    2\n",
            "20638    2\n",
            "20639    2\n",
            "Name: income_cat, Length: 20640, dtype: category\n",
            "Categories (5, int64): [1 < 2 < 3 < 4 < 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "print(len(housing[\"median_income\"].unique()))\n",
        "# Wrong stratify !\n",
        "#strat_train_set, strat_test_set = train_test_split(housing, test_size=0.2, stratify=housing[\"median_income\"], random_state=42)\n",
        "\"\"\"\n",
        "ValueError: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "ffnx9nnN1Tld",
        "outputId": "70164445-037e-446f-89e5-f553946c37d0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12928\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-39f6f10ee684>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhousing\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"median_income\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Wrong stratify !\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mstrat_train_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrat_test_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhousing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhousing\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"median_income\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2870\u001b[0m         \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCVClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2872\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstratify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2874\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_common_namespace_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   1907\u001b[0m         \"\"\"\n\u001b[1;32m   1908\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1909\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1910\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_iter_indices\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   2316\u001b[0m         \u001b[0mclass_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2317\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_counts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2318\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   2319\u001b[0m                 \u001b[0;34m\"The least populated class in y has only 1\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2320\u001b[0m                 \u001b[0;34m\" member, which is too few. The minimum\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NOTES :\n",
        "Stratified Sampling is a method used to split data while preserving the proportions of different classes in each subset (e.g., Train, Validation, Test). This is especially useful when dealing with imbalanced classes.\n",
        "\n",
        "Why is it helpful?\n",
        "\n",
        "- It ensures that each dataset subset contains the same class distribution as the original dataset.\n",
        "- This improves the model's learning performance, especially when working with imbalanced data.\n",
        "------------------------------------------------------------------------------\n",
        "⚠️ERROR NOTES :\n",
        "\n",
        "Handling Continuous Data for Stratified Sampling\n",
        "\n",
        "When the data is continuous, **Stratified Sampling** cannot be directly applied\n",
        "\n",
        "should be at least two rows of the same class ⇒ two classes of the same label\n",
        "\n",
        "If we assume we only have one number of class, where should it be placed?\n",
        "\n",
        "In which dataset??\n",
        "\n",
        "**solution**\n",
        "\n",
        "Define Ranges (Binning):\n",
        "Convert Continuous Value to Classes\n"
      ],
      "metadata": {
        "id": "culu3lZj0JO4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "𓂃🖊 Summary\n",
        "\n",
        "Stratified sampling is useful when dealing with imbalanced datasets, as it ensures an equal distribution of the existing classes. However, if the data is continuous, it must first be converted into classes by binning the values into predefined ranges. Only then can stratified sampling be applied."
      ],
      "metadata": {
        "id": "WC3Ax-1K246M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "_______________________________________________________________________________________________"
      ],
      "metadata": {
        "id": "6y69zjBn6YrV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "→  K-Fold Cross-Validation\n",
        "\n",
        "Divides the data into 5 parts (k=5).\n",
        "Each time, 4 parts are trained and the remaining part is tested\n",
        "\n",
        "The RMSE is calculated for each part and then the mean and standard deviation are calculated"
      ],
      "metadata": {
        "id": "5r669wmn6ayW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold,cross_val_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "X = housing[['median_income','housing_median_age','population','total_rooms']] # Features : Which will be used to predict the price of the house\n",
        "y = housing['median_house_value'] # Target\n",
        "\n",
        "model = LinearRegression() # Create a linear regression model\n",
        "\n",
        "k = 5\n",
        "kf = KFold(n_splits=k,shuffle=True,random_state=42)\n",
        "\"\"\"\n",
        "k = 5: Split the data into 5 folds\n",
        "shuffle=True: Data is shuffled randomly before splitting, preventing bias\n",
        "random_state=42: Ensures that the results are repeated on each run\n",
        "\"\"\"\n",
        "\n",
        "cv_scores = cross_val_score(model,X,y,cv=kf,scoring='neg_root_mean_squared_error')\n",
        "\"\"\"\n",
        "cross_val_score() does:\n",
        "Train the model in 4 parts and test it in the fifth part\n",
        "Calculate the RMSE for each part\n",
        "Returns values ​​negatively (neg_root_mean_squared_error) because cross_val_score() uses negative error values\n",
        "\"\"\"\n",
        "\n",
        "rmse_scores = (-cv_scores) # Convert negative values ​​to positive because RMSE cannot be negative\n",
        "\n",
        "# Print Result\n",
        "print(f'RMSE scores for each fold : {rmse_scores}')\n",
        "print(f'Mean RMSE : {rmse_scores.mean()}')\n",
        "print(f'Standard Deviation of RMSE : {rmse_scores.std()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXU8HHki6lGv",
        "outputId": "e03f0082-bd87-4a13-a46c-bc85c01eca08"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE scores for each fold : [81223.17364865 79504.08481614 81550.91401948 79609.37454749\n",
            " 79349.31733515]\n",
            "Mean RMSE : 80247.37287338135\n",
            "Standard Deviation of RMSE : 939.939298274745\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "------------------------------------------------------------------------------------\n",
        "RMSE (Root Mean Squared Error) :\n",
        "It is a metric used to evaluate the performance of machine learning and regression models\n",
        "\n",
        "The smaller the RMSE, the better the model ✨\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AUDAULOd-LST"
      }
    }
  ]
}