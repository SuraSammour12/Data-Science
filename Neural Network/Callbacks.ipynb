{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Keras Callbacks :\n",
        "\n",
        "Keras Callbacks are powerful tools used during model training to control their execution and improve their performance. They can be thought of as functions that are automatically executed at different stages of training, such as the beginning or end of each epoch, or after updating a batch of data.\n",
        "\n",
        "Why do we use Callbacks?\n",
        "\n",
        "EarlyStopping: Stops training if performance has not improved after a certain number of epochs.\n",
        "\n",
        "ModelCheckpoint: Saves the best version of the model during training.\n",
        "\n",
        "ReduceLROnPlateau: Reduces the learning rate when optimization stops.\n",
        "\n",
        "TensorBoard: Record and visually monitor training data.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3kGM8AbkVIhs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "Using Callbacks during Training"
      ],
      "metadata": {
        "id": "w1l0arTe7QMr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "0wfutdnEVLdM"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download California Housing data\n",
        "dataset = fetch_california_housing()\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(dataset.data, dataset.target, random_state=42)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)"
      ],
      "metadata": {
        "id": "ZYP5dXIfC7GJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data normalization (improve performance by bringing values ​​within an appropriate range)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_valid = scaler.transform(X_valid)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "quIdc25TC8Mv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Wide & Deep Network model\n",
        "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
        "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
        "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
        "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
        "concat = keras.layers.concatenate([input_A, hidden2])\n",
        "output = keras.layers.Dense(1, name=\"output\")(concat)\n",
        "model = keras.models.Model(inputs=[input_A, input_B], outputs=[output])"
      ],
      "metadata": {
        "id": "HWuQEOIZDCgr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model compilation model.compile()\n",
        "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))"
      ],
      "metadata": {
        "id": "dcO8rl36DHFe"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the data to fit the input\n",
        "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
        "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
        "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
        "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]"
      ],
      "metadata": {
        "id": "35YEqiGPDK8Z"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model with Early Stopping and save the best model\n",
        "# The goal of EarlyStopping is to stop model training when performance on the validation set does not improve for a certain period\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_checkpoint.keras\", save_best_only=True)\n",
        "# ModelCheckpoint : save the best model achieved during training. Here, save_best_only=True is specified which means that the model will be saved only if performance improves on the validation set\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n",
        "# patience=3 : If the model does not improve its performance over 3 epochs, we stop training to avoid overtraining or overlearning\n",
        "# restore_best_weights=True means that when training stops, the best weights of the model (which achieved the best accuracy or performance during the training period) will be retrieved\n",
        "\"\"\"\n",
        "The goal of the callbacks:\n",
        "The first callback (checkpoint_cb) is used to save the best model achieved during training.\n",
        "The second callback (early_stopping_cb) is used to stop training early if the performance doesn't improve over a certain number of epochs (in this case, 3 epochs).\n",
        "\"\"\"\n",
        "history = model.fit(\n",
        "    (X_train_A, X_train_B), y_train, epochs=20,\n",
        "    validation_data=((X_valid_A, X_valid_B), y_valid),\n",
        "    callbacks=[checkpoint_cb, early_stopping_cb]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGKTRaLZDOgF",
        "outputId": "9ac1c028-696d-4248-ae44-e077ce98a7c4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 3.2818 - val_loss: 4.3430\n",
            "Epoch 2/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.9533 - val_loss: 1.1293\n",
            "Epoch 3/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.7291 - val_loss: 0.6764\n",
            "Epoch 4/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.6678 - val_loss: 0.5903\n",
            "Epoch 5/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.6206 - val_loss: 0.5554\n",
            "Epoch 6/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.5627 - val_loss: 0.5254\n",
            "Epoch 7/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5435 - val_loss: 0.4993\n",
            "Epoch 8/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.5340 - val_loss: 0.4798\n",
            "Epoch 9/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.4992 - val_loss: 0.4651\n",
            "Epoch 10/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4731 - val_loss: 0.4493\n",
            "Epoch 11/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.4728 - val_loss: 0.4362\n",
            "Epoch 12/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.4658 - val_loss: 0.4281\n",
            "Epoch 13/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4540 - val_loss: 0.4225\n",
            "Epoch 14/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4601 - val_loss: 0.4173\n",
            "Epoch 15/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4521 - val_loss: 0.4132\n",
            "Epoch 16/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4476 - val_loss: 0.4101\n",
            "Epoch 17/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4242 - val_loss: 0.4084\n",
            "Epoch 18/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4398 - val_loss: 0.4040\n",
            "Epoch 19/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.4547 - val_loss: 0.4021\n",
            "Epoch 20/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.4316 - val_loss: 0.3992\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve the best saved model\n",
        "tuned_model = keras.models.load_model(\"my_checkpoint.keras\")"
      ],
      "metadata": {
        "id": "3MrDQetuDVY0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on test data\n",
        "mse_test = tuned_model.evaluate((X_test_A, X_test_B), y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OF-_WXjGDknD",
        "outputId": "8be9f2bc-cce9-46ef-e3ee-0b1b47527ff2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4313\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting some new values\n",
        "y_pred = tuned_model.predict((X_new_A, X_new_B))\n",
        "print(\"Predictions:\", y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuhIoKi0Dn_r",
        "outputId": "8df8f772-c5c9-4a50-f66c-275b08d1d019"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
            "Predictions: [[0.3465656]\n",
            " [1.8708789]\n",
            " [3.200811 ]]\n"
          ]
        }
      ]
    }
  ]
}